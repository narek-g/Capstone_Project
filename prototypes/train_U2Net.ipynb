{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50dd497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d0e86b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# import torchvision\n",
    "# from torch.autograd import Variable\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torchvision import transforms, utils\n",
    "# import torch.optim as optim\n",
    "# import torchvision.transforms as standard_transforms\n",
    "\n",
    "# import numpy as np\n",
    "# import glob\n",
    "# import os\n",
    "# import pickle\n",
    "# import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9c05085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import yaml\n",
    "import cv2\n",
    "import pprint\n",
    "import traceback\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98db4453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "468d9fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/Users/narekgeghamyan/Classes/MLE_bootcamp/Capstone_Project')\n",
    "\n",
    "from data.custom_dataset_data_loader import CustomDatasetDataLoader, sample_data\n",
    "from model import U2NET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a84c7de",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca03a6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/narekgeghamyan/local_data/capstone_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91ad22a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0f1d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1737f0a5",
   "metadata": {},
   "source": [
    "### Set-up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436a9188",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataLoader:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def initialize(self, opt):\n",
    "        self.opt = opt\n",
    "        pass\n",
    "\n",
    "    def load_data():\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab064e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateDataset(opt):\n",
    "    dataset = None\n",
    "    from data.aligned_dataset import AlignedDataset\n",
    "    dataset = AlignedDataset()\n",
    "\n",
    "    print(\"dataset [%s] was created\" % (dataset.name()))\n",
    "    dataset.initialize(opt)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b501e758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sampler(dataset, shuffle, distributed):\n",
    "    if distributed:\n",
    "        return torch.utils.data.distributed.DistributedSampler(dataset, shuffle=shuffle)\n",
    "\n",
    "    if shuffle:\n",
    "        return torch.utils.data.RandomSampler(dataset)\n",
    "\n",
    "    else:\n",
    "        return torch.utils.data.SequentialSampler(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ced5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0197d117",
   "metadata": {},
   "outputs": [],
   "source": [
    "nThreads = 1\n",
    "serial_batches = False\n",
    "distributed = False # not multi-gpu training \n",
    "batchSize = 2 \n",
    "\n",
    "class CustomDatasetDataLoader(BaseDataLoader):\n",
    "    def name(self):\n",
    "        return 'CustomDatasetDataLoader'\n",
    "\n",
    "    def initialize(self, opt):\n",
    "        BaseDataLoader.initialize(self, opt)\n",
    "        self.dataset = CreateDataset(opt)\n",
    "        self.dataloader = torch.utils.data.DataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=batchSize,\n",
    "            sampler=data_sampler(self.dataset,serial_batches, distributed),\n",
    "            num_workers=int(nThreads),\n",
    "            pin_memory=True)\n",
    "\n",
    "    def get_loader(self):\n",
    "        return self.dataloader\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46487397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(loader):\n",
    "    while True:\n",
    "        for batch in loader:\n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34f37d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b675ee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataloader = CustomDatasetDataLoader()\n",
    "custom_dataloader.initialize(opt)\n",
    "loader = custom_dataloader.get_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af21cdf9",
   "metadata": {},
   "source": [
    "### Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "509f3f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- 1. define loss function --------\n",
    "\n",
    "#bce_loss = nn.BCELoss(reduction='mean')\n",
    "loss_fxn = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "def loss_fuction(d0, d1, d2, d3, d4, d5, d6, labels_v):\n",
    "\n",
    "\tloss0 = loss_fxn(d0,labels_v)\n",
    "\tloss1 = loss_fxn(d1,labels_v)\n",
    "\tloss2 = loss_fxn(d2,labels_v)\n",
    "\tloss3 = loss_fxn(d3,labels_v)\n",
    "\tloss4 = loss_fxn(d4,labels_v)\n",
    "\tloss5 = loss_fxn(d5,labels_v)\n",
    "\tloss6 = loss_fxn(d6,labels_v)\n",
    "\n",
    "\tloss = loss0 + loss1 + loss2 + loss3 + loss4 + loss5 + loss6\n",
    "\tprint(\"l0: %3f, l1: %3f, l2: %3f, l3: %3f, l4: %3f, l5: %3f, l6: %3f\\n\"%(loss0.data.item(),loss1.data.item(),loss2.data.item(),loss3.data.item(),loss4.data.item(),loss5.data.item(),loss6.data.item()))\n",
    "\n",
    "\treturn loss0, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c33e2c",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb94cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the net\n",
    "model_name = 'u2net'\n",
    "if(model_name=='u2net'):\n",
    "#     net = U2NET(3, 1)\n",
    "    net = U2NET(in_ch=3, out_ch=4)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()\n",
    "    print('Cuda available..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb605208",
   "metadata": {},
   "source": [
    "### Define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40903ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065624aa",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d81555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = 3\n",
    "ite_num = 0\n",
    "running_loss = 0.0\n",
    "running_tar_loss = 0.0\n",
    "ite_num4val = 0\n",
    "save_frq = 3 # save every 2 iterations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a7ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0, epoch_num):\n",
    "    net.train()\n",
    "\n",
    "    for i, data in enumerate(salobj_dataloader):\n",
    "        ite_num = ite_num + 1\n",
    "        ite_num4val = ite_num4val + 1\n",
    "\n",
    "        inputs, labels = data['image'], data['label']\n",
    "\n",
    "        inputs = inputs.type(torch.FloatTensor)\n",
    "        labels = labels.type(torch.FloatTensor)\n",
    "\n",
    "        # wrap them in Variable\n",
    "        if torch.cuda.is_available():\n",
    "            inputs_v, labels_v = Variable(inputs.cuda(), requires_grad=False), Variable(labels.cuda(),\n",
    "                                                                                        requires_grad=False)\n",
    "        else:\n",
    "            inputs_v, labels_v = Variable(inputs, requires_grad=False), Variable(labels, requires_grad=False)\n",
    "\n",
    "        # y zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        d0, d1, d2, d3, d4, d5, d6 = net(inputs_v)\n",
    "        loss2, loss = loss_fuction(d0, d1, d2, d3, d4, d5, d6, labels_v)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # # print statistics\n",
    "        running_loss += loss.data.item()\n",
    "        running_tar_loss += loss2.data.item()\n",
    "\n",
    "        # del temporary outputs and loss\n",
    "        del d0, d1, d2, d3, d4, d5, d6, loss2, loss\n",
    "\n",
    "        print(\"[epoch: %3d/%3d, batch: %5d/%5d, ite: %d] train loss: %3f, tar: %3f \" % (\n",
    "        epoch + 1, epoch_num, (i + 1) * batch_size_train, train_num, ite_num, running_loss / ite_num4val, running_tar_loss / ite_num4val))\n",
    "\n",
    "        if ite_num % save_frq == 0:\n",
    "\n",
    "            torch.save(net.state_dict(), model_dir + model_name+\"_bce_itr_%d_train_%3f_tar_%3f.pth\" % (ite_num, running_loss / ite_num4val, running_tar_loss / ite_num4val))\n",
    "            running_loss = 0.0\n",
    "            running_tar_loss = 0.0\n",
    "            net.train()  # resume train\n",
    "            ite_num4val = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-nightly",
   "language": "python",
   "name": "pytorch-nightly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
