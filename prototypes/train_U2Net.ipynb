{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb12c912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "694ab5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as standard_transforms\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c730e159",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/Users/narekgeghamyan/Classes/MLE_bootcamp/Capstone_Project')\n",
    "from data_loader import Rescale\n",
    "from data_loader import RescaleT\n",
    "from data_loader import RandomCrop\n",
    "from data_loader import ToTensor\n",
    "from data_loader import ToTensorLab\n",
    "from data_loader import SalObjDataset\n",
    "\n",
    "from model import U2NET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487349da",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d627d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/narekgeghamyan/local_data/capstone_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aa039ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "filehandler = open('u2net_684_train_images.pkl', 'rb')\n",
    "trn_images = pickle.load(filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "944ca142",
   "metadata": {},
   "outputs": [],
   "source": [
    "filehandler = open('u2net_684_seg_images.pkl', 'rb')\n",
    "seg_images = pickle.load(filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0fb39f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filehandler = open('u2net_684_img_name_list.pkl', 'rb')\n",
    "img_name_list = pickle.load(filehandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "974ac677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "684"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a34960a",
   "metadata": {},
   "source": [
    "### Set-up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2e43cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataLoader:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def initialize(self, opt):\n",
    "        self.opt = opt\n",
    "        pass\n",
    "\n",
    "    def load_data():\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66a0edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateDataset(opt):\n",
    "    dataset = None\n",
    "    from data.aligned_dataset import AlignedDataset\n",
    "    dataset = AlignedDataset()\n",
    "\n",
    "    print(\"dataset [%s] was created\" % (dataset.name()))\n",
    "    dataset.initialize(opt)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1946edbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sampler(dataset, shuffle, distributed):\n",
    "    if distributed:\n",
    "        return torch.utils.data.distributed.DistributedSampler(dataset, shuffle=shuffle)\n",
    "\n",
    "    if shuffle:\n",
    "        return torch.utils.data.RandomSampler(dataset)\n",
    "\n",
    "    else:\n",
    "        return torch.utils.data.SequentialSampler(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d665c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b0dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nThreads = 1\n",
    "serial_batches = False\n",
    "distributed = False # not multi-gpu training \n",
    "batchSize = 2 \n",
    "\n",
    "class CustomDatasetDataLoader(BaseDataLoader):\n",
    "    def name(self):\n",
    "        return 'CustomDatasetDataLoader'\n",
    "\n",
    "    def initialize(self, opt):\n",
    "        BaseDataLoader.initialize(self, opt)\n",
    "        self.dataset = CreateDataset(opt)\n",
    "        self.dataloader = torch.utils.data.DataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=batchSize,\n",
    "            sampler=data_sampler(self.dataset,serial_batches, distributed),\n",
    "            num_workers=int(nThreads),\n",
    "            pin_memory=True)\n",
    "\n",
    "    def get_loader(self):\n",
    "        return self.dataloader\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10322957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(loader):\n",
    "    while True:\n",
    "        for batch in loader:\n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c2acf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataloader = CustomDatasetDataLoader()\n",
    "custom_dataloader.initialize(opt)\n",
    "loader = custom_dataloader.get_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3012b22f",
   "metadata": {},
   "source": [
    "### Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07b7778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- 1. define loss function --------\n",
    "\n",
    "#bce_loss = nn.BCELoss(reduction='mean')\n",
    "loss_fxn = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "def loss_fuction(d0, d1, d2, d3, d4, d5, d6, labels_v):\n",
    "\n",
    "\tloss0 = loss_fxn(d0,labels_v)\n",
    "\tloss1 = loss_fxn(d1,labels_v)\n",
    "\tloss2 = loss_fxn(d2,labels_v)\n",
    "\tloss3 = loss_fxn(d3,labels_v)\n",
    "\tloss4 = loss_fxn(d4,labels_v)\n",
    "\tloss5 = loss_fxn(d5,labels_v)\n",
    "\tloss6 = loss_fxn(d6,labels_v)\n",
    "\n",
    "\tloss = loss0 + loss1 + loss2 + loss3 + loss4 + loss5 + loss6\n",
    "\tprint(\"l0: %3f, l1: %3f, l2: %3f, l3: %3f, l4: %3f, l5: %3f, l6: %3f\\n\"%(loss0.data.item(),loss1.data.item(),loss2.data.item(),loss3.data.item(),loss4.data.item(),loss5.data.item(),loss6.data.item()))\n",
    "\n",
    "\treturn loss0, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbf91c5",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23e391b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the net\n",
    "model_name = 'u2net'\n",
    "if(model_name=='u2net'):\n",
    "#     net = U2NET(3, 1)\n",
    "    net = U2NET(in_ch=3, out_ch=4)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()\n",
    "    print('Cuda available..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94841ec",
   "metadata": {},
   "source": [
    "### Define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5caf3b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d29d0f7",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82ac871",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = 3\n",
    "ite_num = 0\n",
    "running_loss = 0.0\n",
    "running_tar_loss = 0.0\n",
    "ite_num4val = 0\n",
    "save_frq = 3 # save every 2 iterations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3238a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0, epoch_num):\n",
    "    net.train()\n",
    "\n",
    "    for i, data in enumerate(salobj_dataloader):\n",
    "        ite_num = ite_num + 1\n",
    "        ite_num4val = ite_num4val + 1\n",
    "\n",
    "        inputs, labels = data['image'], data['label']\n",
    "\n",
    "        inputs = inputs.type(torch.FloatTensor)\n",
    "        labels = labels.type(torch.FloatTensor)\n",
    "\n",
    "        # wrap them in Variable\n",
    "        if torch.cuda.is_available():\n",
    "            inputs_v, labels_v = Variable(inputs.cuda(), requires_grad=False), Variable(labels.cuda(),\n",
    "                                                                                        requires_grad=False)\n",
    "        else:\n",
    "            inputs_v, labels_v = Variable(inputs, requires_grad=False), Variable(labels, requires_grad=False)\n",
    "\n",
    "        # y zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        d0, d1, d2, d3, d4, d5, d6 = net(inputs_v)\n",
    "        loss2, loss = loss_fuction(d0, d1, d2, d3, d4, d5, d6, labels_v)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # # print statistics\n",
    "        running_loss += loss.data.item()\n",
    "        running_tar_loss += loss2.data.item()\n",
    "\n",
    "        # del temporary outputs and loss\n",
    "        del d0, d1, d2, d3, d4, d5, d6, loss2, loss\n",
    "\n",
    "        print(\"[epoch: %3d/%3d, batch: %5d/%5d, ite: %d] train loss: %3f, tar: %3f \" % (\n",
    "        epoch + 1, epoch_num, (i + 1) * batch_size_train, train_num, ite_num, running_loss / ite_num4val, running_tar_loss / ite_num4val))\n",
    "\n",
    "        if ite_num % save_frq == 0:\n",
    "\n",
    "            torch.save(net.state_dict(), model_dir + model_name+\"_bce_itr_%d_train_%3f_tar_%3f.pth\" % (ite_num, running_loss / ite_num4val, running_tar_loss / ite_num4val))\n",
    "            running_loss = 0.0\n",
    "            running_tar_loss = 0.0\n",
    "            net.train()  # resume train\n",
    "            ite_num4val = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-nightly",
   "language": "python",
   "name": "pytorch-nightly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
