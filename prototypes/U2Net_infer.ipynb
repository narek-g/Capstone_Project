{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da3a0f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c17530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "397d9936",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')\n",
    "from data.base_dataset import Normalize_image\n",
    "from utils.saving_utils import load_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a2339de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import U2NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb578615",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "image_dir = \"/Users/narekgeghamyan/Classes/MLE_bootcamp/Capstone_Project/input_images\"\n",
    "result_dir = \"/Users/narekgeghamyan/Classes/MLE_bootcamp/Capstone_Project/output_images\"\n",
    "# checkpoint_path = \"/Users/narekgeghamyan/Classes/MLE_bootcamp/Capstone_Project/results/training_cloth_segm_u2net_exp1/checkpoints/itr_00001000_u2net.pth\"\n",
    "checkpoint_path = \"/Users/narekgeghamyan/Classes/MLE_bootcamp/Capstone_Project/results/cloth_segm_u2net_latest.pth\"\n",
    "do_palette = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b91c75cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_palette(num_cls):\n",
    "    \"\"\"Returns the color map for visualizing the segmentation mask.\n",
    "    Args:\n",
    "        num_cls: Number of classes\n",
    "    Returns:\n",
    "        The color map\n",
    "    \"\"\"\n",
    "    n = num_cls\n",
    "    palette = [0] * (n * 3)\n",
    "    for j in range(0, n):\n",
    "        lab = j\n",
    "        palette[j * 3 + 0] = 0\n",
    "        palette[j * 3 + 1] = 0\n",
    "        palette[j * 3 + 2] = 0\n",
    "        i = 0\n",
    "        while lab:\n",
    "            palette[j * 3 + 0] |= ((lab >> 0) & 1) << (7 - i)\n",
    "            palette[j * 3 + 1] |= ((lab >> 1) & 1) << (7 - i)\n",
    "            palette[j * 3 + 2] |= ((lab >> 2) & 1) << (7 - i)\n",
    "            i += 1\n",
    "            lab >>= 3\n",
    "    return palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e954270",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_list = []\n",
    "transforms_list += [transforms.ToTensor()]\n",
    "transforms_list += [Normalize_image(0.5, 0.5)]\n",
    "transform_rgb = transforms.Compose(transforms_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f27ffd2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----checkpoints loaded from path: /Users/narekgeghamyan/Classes/MLE_bootcamp/Capstone_Project/results/cloth_segm_u2net_latest.pth----\n"
     ]
    }
   ],
   "source": [
    "net = U2NET(in_ch=3, out_ch=4)\n",
    "net = load_checkpoint_mgpu(net, checkpoint_path)\n",
    "# net = net.to(device)\n",
    "# net = net.eval()\n",
    "\n",
    "palette = get_palette(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cdc2f829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [4:21:28<00:00, 5229.37s/it]\u001b[A\n",
      "\n",
      " 33%|██████████████████████████████████████▋                                                                             | 1/3 [00:26<00:52, 26.25s/it]\u001b[A\n",
      " 67%|█████████████████████████████████████████████████████████████████████████████▎                                      | 2/3 [00:41<00:19, 19.79s/it]\u001b[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:51<00:00, 15.14s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "images_list = sorted(os.listdir(image_dir))\n",
    "pbar = tqdm(total=len(images_list))\n",
    "for image_name in images_list:\n",
    "    img = Image.open(os.path.join(image_dir, image_name)).convert(\"RGB\")\n",
    "    image_tensor = transform_rgb(img)\n",
    "    image_tensor = torch.unsqueeze(image_tensor, 0)\n",
    "\n",
    "    output_tensor = net(image_tensor) #net(image_tensor.to(device))\n",
    "    output_tensor = F.log_softmax(output_tensor[0], dim=1)\n",
    "    output_tensor = torch.max(output_tensor, dim=1, keepdim=True)[1]\n",
    "    output_tensor = torch.squeeze(output_tensor, dim=0)\n",
    "    output_tensor = torch.squeeze(output_tensor, dim=0)\n",
    "    output_arr = output_tensor.cpu().numpy()\n",
    "\n",
    "    output_img = Image.fromarray(output_arr.astype(\"uint8\"), mode=\"L\")\n",
    "    if do_palette:\n",
    "        output_img.putpalette(palette)\n",
    "    output_img.save(os.path.join(result_dir, image_name[:-3] + \"png\"))\n",
    "\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb3bde0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-nightly",
   "language": "python",
   "name": "pytorch-nightly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
